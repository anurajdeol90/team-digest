name: Weekly Digest

on:
  schedule:
    - cron: "0 8 * * 1"   # Mondays at 08:00 (uses TZ below)
  workflow_dispatch:
    inputs:
      input_dir:
        description: "Override INPUT_DIR (repo-relative or absolute; e.g., logs or $GITHUB_WORKSPACE/logs)"
        required: false
        type: string
      week_scope:
        description: "Week to summarize: last (default) or this"
        required: false
        default: "last"
        type: string

jobs:
  run:
    runs-on: ubuntu-latest
    env:
      TZ: ${{ vars.DIGEST_TZ || 'UTC' }}   # e.g. "America/Chicago" or "UTC"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install team-digest
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install "team-digest>=1.1.6,<2"

      # ---------- Resolve INPUT_DIR robustly ----------
      - name: Resolve INPUT_DIR (override → repo var → logs/)
        id: resolve
        shell: bash
        run: |
          set -euo pipefail
          # 1) Candidate from dispatch or repo variable
          CANDIDATE="${{ github.event.inputs.input_dir }}"
          if [ -z "${CANDIDATE:-}" ] && [ -n "${{ vars.DIGEST_INPUT_DIR }}" ]; then
            CANDIDATE="${{ vars.DIGEST_INPUT_DIR }}"
          fi
          [ -z "${CANDIDATE:-}" ] && CANDIDATE="logs"

          # 2) Expand literal "$GITHUB_WORKSPACE/..." if typed into input
          case "$CANDIDATE" in
            '$GITHUB_WORKSPACE'/*)
              CANDIDATE="${GITHUB_WORKSPACE}${CANDIDATE#\$GITHUB_WORKSPACE}"
              ;;
          esac

          # 3) If still relative, make it repo-relative
          case "$CANDIDATE" in
            /*)  INPUT_DIR="$CANDIDATE" ;;
            *)   INPUT_DIR="${GITHUB_WORKSPACE%/}/$CANDIDATE" ;;
          esac

          echo "Resolved INPUT_DIR=$INPUT_DIR"
          echo "INPUT_DIR=$INPUT_DIR" >> "$GITHUB_ENV"

      # ---------- Compute week window (Mon..Sun) in bash ----------
      - name: Compute week window (Mon..Sun)
        shell: bash
        run: |
          set -euo pipefail
          scope="${{ github.event.inputs.week_scope }}"
          [ -z "${scope:-}" ] && scope="last"
          scope="${scope,,}"  # to lower

          if [[ "$scope" == this* ]]; then
            MON=$(date +%F -d "monday this week")
          else
            MON=$(date +%F -d "monday last week")
          fi
          SUN=$(date +%F -d "$MON +6 days")

          echo "FROM=$MON" | tee -a "$GITHUB_ENV"
          echo "TO=$SUN"   | tee -a "$GITHUB_ENV"
          echo "Window: $MON .. $SUN"

      # ---------- Deep diagnostics so we can see what's actually checked out ----------
      - name: Diagnostics — repo & logs presence
        shell: bash
        run: |
          set -euo pipefail
          echo "pwd=$(pwd)"
          echo "GITHUB_WORKSPACE=$GITHUB_WORKSPACE"
          echo
          echo "Repo root (depth 2):"
          find . -maxdepth 2 -type d -printf '%p\n' | sort
          echo
          echo "Tracked files under logs/ (git):"
          git ls-files logs || true
          echo
          echo "List INPUT_DIR content:"
          if [ -d "$INPUT_DIR" ]; then
            ls -la "$INPUT_DIR" || true
          else
            echo "(INPUT_DIR does not exist)"
          fi

      # ---------- Normalize note files and retime mtime by filename date ----------
      - name: Normalize / retime logs (safe edits)
        shell: bash
        run: |
          set -euo pipefail
          shopt -s nullglob
          for f in "$INPUT_DIR"/notes-????-??-??.*; do
            base="$(basename "$f")"
            datepart="${base#notes-}"; datepart="${datepart%%.*}"
            # Stamp mtime to noon UTC to avoid DST edges
            touch -m -d "${datepart} 12:00:00" "$f" || true
            # Normalize newlines/bullets/escapes/smart dashes
            sed -i \
              -e 's/\r$//' \
              -e 's/•\t/- /g' \
              -e 's/• /- /g' \
              -e 's/\\#/#/g' \
              -e 's/\\\[/[/' \
              -e 's/\\-/-/g' \
              -e 's/–/-/g' \
              -e 's/—/-/g' \
              "$f" || true
          done

      # ---------- Filename-date matcher to prove which files fall into window ----------
      - name: Diagnostics — match notes by filename date
        shell: bash
        run: |
          set -euo pipefail
          echo "Matching notes-YYYY-MM-DD.* within $FROM..$TO (by filename date):"
          root="${INPUT_DIR%/}"
          found=()
          shopt -s nullglob
          for path in "$root"/notes-*; do
            name="$(basename "$path")"
            if [[ "$name" =~ ^notes-([0-9]{4}-[0-9]{2}-[0-9]{2})\.(md|markdown|txt)$ ]]; then
              d="${BASH_REMATCH[1]}"
              # lexicographic compare OK for ISO dates
              if [[ "$d" >="$FROM" && "$d" <="$TO" ]]; then
                found+=("$name")
              fi
            fi
          done
          if ((${#found[@]})); then
            IFS=$'\n' sorted=($(printf '%s\n' "${found[@]}" | sort)); unset IFS
            echo "MATCHES: ${sorted[*]}"
          else
            echo "MATCHES: (none)"
          fi

      # ---------- Generate digest ----------
      - name: Generate weekly digest
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p outputs
          team-digest --input "$INPUT_DIR" --from "$FROM" --to "$TO" --format md -o outputs/weekly.md
          echo '---- Preview (first 60 lines) ----'
          head -n 60 outputs/weekly.md || true

      # ---------- Group Actions by priority (awk; parser-safe) ----------
      - name: Sort Actions by priority (best effort)
        shell: bash
        continue-on-error: true
        run: |
          set -euo pipefail
          [ -f outputs/weekly.md ] || exit 0
          awk '
          BEGIN { in=0; hc=mc=lc=nc=oc=0 }
          function flush_block() {
            for (i=1;i<=hc;i++) print high[i]
            for (i=1;i<=mc;i++) print med[i]
            for (i=1;i<=lc;i++) print low[i]
            for (i=1;i<=nc;i++) print none[i]
            for (i=1;i<=oc;i++) print other[i]
          }
          function reset_block() { hc=mc=lc=nc=oc=0; delete high; delete med; delete low; delete none; delete other }
          {
            if (!in) {
              print
              if ($0 ~ /^##[[:space:]]+Actions[[:space:]]*$/) { in=1; next }
            } else {
              if ($0 ~ /^##[[:space:]]+/) { flush_block(); reset_block(); in=0; print; next }
              if ($0 ~ /^[[:space:]]*[-*][[:space:]]+/) {
                s=tolower($0)
                if (s ~ /\[high\]/)       high[++hc]=$0
                else if (s ~ /\[medium\]/) med[++mc]=$0
                else if (s ~ /\[low\]/)    low[++lc]=$0
                else                        none[++nc]=$0
              } else {
                other[++oc]=$0
              }
            }
          }
          END { if (in) flush_block() }
          ' outputs/weekly.md > outputs/weekly.md.tmp && mv outputs/weekly.md.tmp outputs/weekly.md

      # ---------- Slack (optional) ----------
      - name: Resolve Slack webhook (optional)
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${{ secrets.SLACK_WEBHOOK_URL }}" ]; then
            echo "SLACK_WEBHOOK=${{ secrets.SLACK_WEBHOOK_URL }}" >> "$GITHUB_ENV"
          elif [ -n "${{ secrets.SLACK_WEBHOOK }}" ]; then
            echo "SLACK_WEBHOOK=${{ secrets.SLACK_WEBHOOK }}" >> "$GITHUB_ENV"
          else
            echo "SLACK_WEBHOOK=" >> "$GITHUB_ENV"
          fi

      - name: Post to Slack (if webhook is set)
        if: env.SLACK_WEBHOOK != ''
        shell: bash
        run: |
          set -euo pipefail
          PAYLOAD=$(jq -Rs --arg pre '```' '{text: ($pre + . + $pre)}' < outputs/weekly.md)
          curl -fsSL -H 'Content-Type: application/json' --data-raw "$PAYLOAD" "$SLACK_WEBHOOK"

      # ---------- Artifact ----------
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: weekly-digest
          path: outputs/**
