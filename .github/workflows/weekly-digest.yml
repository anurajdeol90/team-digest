name: Weekly Digest

on:
  schedule:
    - cron: "0 8 * * 1"  # Mondays at 08:00 (uses TZ below)
  workflow_dispatch:
    inputs:
      input_dir:
        description: "Override INPUT_DIR (repo-relative or absolute; e.g. logs or $GITHUB_WORKSPACE/logs)"
        required: false
        type: string
      week_scope:
        description: "Week to summarize: last (default) or this"
        required: false
        default: "last"
        type: string

jobs:
  run:
    runs-on: ubuntu-latest
    env:
      TZ: ${{ vars.DIGEST_TZ || 'UTC' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install team-digest
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install "team-digest>=1.1.6,<2"

      # ---------- CRITICAL: resolve INPUT_DIR with expansion & absolute path ----------
      - name: Resolve INPUT_DIR (override → repo var → logs/)
        id: resolve
        shell: bash
        run: |
          set -euo pipefail

          # 1) Gather candidate
          CANDIDATE="${{ github.event.inputs.input_dir }}"
          if [ -z "${CANDIDATE:-}" ] && [ -n "${{ vars.DIGEST_INPUT_DIR }}" ]; then
            CANDIDATE="${{ vars.DIGEST_INPUT_DIR }}"
          fi
          [ -z "${CANDIDATE:-}" ] && CANDIDATE="logs"

          # 2) Expand $GITHUB_WORKSPACE literally typed by a user (e.g. "$GITHUB_WORKSPACE/logs")
          case "$CANDIDATE" in
            '$GITHUB_WORKSPACE'/*)
              CANDIDATE="${GITHUB_WORKSPACE}${CANDIDATE#\$GITHUB_WORKSPACE}"
              ;;
          esac

          # 3) If relative, treat it as repo-relative
          if [[ "$CANDIDATE" != /* ]]; then
            CANDIDATE="${GITHUB_WORKSPACE%/}/$CANDIDATE"
          fi

          # 4) Canonicalize (best-effort; do not fail if it doesn't exist)
          ABS="$(python - <<'PY'
import os, sys, pathlib
p = pathlib.Path(sys.argv[1])
try:
  print(p.resolve())
except Exception:
  print(p)  # fallback
PY
"$CANDIDATE")"

          echo "Resolved INPUT_DIR=$ABS"
          printf 'INPUT_DIR=%s\n' "$ABS" >> "$GITHUB_ENV"

      # ---------- Week window (Mon..Sun) ----------
      - name: Compute week window (Mon..Sun)
        shell: bash
        env:
          WEEK_SCOPE: ${{ github.event.inputs.week_scope || 'last' }}
        run: |
          set -euo pipefail
          scope="${WEEK_SCOPE:-last}"
          scope="${scope,,}"
          if [[ "$scope" == this* ]]; then
            MON=$(date +%F -d "monday this week")
          else
            MON=$(date +%F -d "monday last week")
          fi
          SUN=$(date +%F -d "$MON +6 days")
          echo "FROM=$MON" | tee -a "$GITHUB_ENV"
          echo "TO=$SUN"   | tee -a "$GITHUB_ENV"
          echo "Window: $MON .. $SUN"

      # ---------- Deep diagnostics so we can see what's actually checked out ----------
      - name: Diagnostics — repo & logs presence
        shell: bash
        run: |
          set -euo pipefail
          echo "pwd=$(pwd)"
          echo "GITHUB_WORKSPACE=$GITHUB_WORKSPACE"
          echo
          echo "Repo root (depth 2):"
          find . -maxdepth 2 -type d -printf '%p\n' | sort
          echo
          echo "Tracked files under logs/ (git):"
          git ls-files logs || true
          echo
          echo "List INPUT_DIR content:"
          if [ -d "$INPUT_DIR" ]; then
            ls -la "$INPUT_DIR" || true
          else
            echo "(INPUT_DIR does not exist)"
          fi

      # ---------- Normalize note files and retime mtime by filename date ----------
      - name: Normalize / retime logs (safe edits)
        if: ${{ success() }}
        shell: bash
        run: |
          set -euo pipefail
          shopt -s nullglob
          for f in "$INPUT_DIR"/notes-????-??-??.*; do
            base="$(basename "$f")"
            datepart="${base#notes-}"; datepart="${datepart%%.*}"
            # Stamp mtime to noon UTC to avoid DST edges
            touch -m -d "${datepart} 12:00:00" "$f" || true
            # Normalize newlines/bullets/escapes/smart dashes
            sed -i \
              -e 's/\r$//' \
              -e 's/•\t/- /g' \
              -e 's/• /- /g' \
              -e 's/\\#/#/g' \
              -e 's/\\\[/[/' \
              -e 's/\\-/-/g' \
              -e 's/–/-/g' \
              -e 's/—/-/g' \
              "$f" || true
          done

      # ---------- Filename-date matcher to prove which files fall in the Mon..Sun window ----------
      - name: Diagnostics — match notes by filename date
        shell: bash
        run: |
          set -euo pipefail
          echo "Matching notes-YYYY-MM-DD.* within $FROM..$TO (by filename date):"
          root="${INPUT_DIR%/}"
          found=()
          shopt -s nullglob
          for path in "$root"/notes-*; do
            name="$(basename "$path")"
            if [[ "$name" =~ ^notes-([0-9]{4}-[0-9]{2}-[0-9]{2})\.(md|markdown|txt)$ ]]; then
              d="${BASH_REMATCH[1]}"
              if [[ "$d" >="$FROM" && "$d" <="$TO" ]]; then
                found+=("$name")
              fi
            fi
          done
          if ((${#found[@]})); then
            IFS=$'\n' sorted=($(printf '%s\n' "${found[@]}" | sort)); unset IFS
            echo "MATCHES: ${sorted[*]}"
          else
            echo "MATCHES: (none)"
          fi

      # ---------- Generate digest ----------
      - name: Generate weekly digest
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p outputs
          team-digest --input "$INPUT_DIR" --from "$FROM" --to "$TO" --format md -o outputs/weekly.md
          echo '---- Preview (first 60 lines) ----'
          head -n 60 outputs/weekly.md || true

      # ---------- Optional: sort Actions by priority ----------
      - name: Sort “Actions” by priority (best effort)
        shell: bash
        continue-on-error: true
        run: |
          python <<'PY'
import re, io, sys
p = "outputs/weekly.md"
try:
  t = io.open(p, "r", encoding="utf-8").read()
except FileNotFoundError:
  sys.exit(0)

sec = re.search(r'^##\s+Actions\s*$', t, re.M)
if not sec:
  sys.exit(0)
start = sec.end()
nxt = re.search(r'^##\s+\w+', t[start:], re.M)
end = start + (nxt.start() if nxt else len(t)-start)
block = t[start:end]

lines = block.splitlines()
bullets = [ln for ln in lines if re.match(r'^\s*[-*]\s+', ln)]
others  = [ln for ln in lines if ln not in bullets]

def prio_key(ln: str) -> int:
  s = ln.lower()
  if "[high]" in s: return 0
  if "[medium]" in s: return 1
  if "[low]" in s: return 2
  return 3

ordered = sorted(bullets, key=prio_key)
joined = "\n".join(ordered + ([""] if ordered and (others and others[0].strip()) else []) + others)
new = t[:start] + "\n" + joined.strip("\n") + "\n" + t[end:]
io.open(p, "w", encoding="utf-8").write(new)
PY

      # ---------- Slack (optional) ----------
      - name: Resolve Slack webhook (optional)
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${{ secrets.SLACK_WEBHOOK_URL }}" ]; then
            echo "SLACK_WEBHOOK=${{ secrets.SLACK_WEBHOOK_URL }}" >> "$GITHUB_ENV"
          elif [ -n "${{ secrets.SLACK_WEBHOOK }}" ]; then
            echo "SLACK_WEBHOOK=${{ secrets.SLACK_WEBHOOK }}" >> "$GITHUB_ENV"
          else
            echo "SLACK_WEBHOOK=" >> "$GITHUB_ENV"
          fi

      - name: Post to Slack (if webhook is set)
        if: env.SLACK_WEBHOOK != ''
        shell: bash
        run: |
          set -euo pipefail
          PAYLOAD=$(jq -Rs --arg pre '```' '{text: ($pre + . + $pre)}' < outputs/weekly.md)
          curl -fsSL -H 'Content-Type: application/json' --data-raw "$PAYLOAD" "$SLACK_WEBHOOK"

      # ---------- Artifact ----------
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: weekly-digest
          path: outputs/**
