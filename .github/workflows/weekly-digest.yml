name: Weekly Digest

on:
  schedule:
    - cron: "0 8 * * 1"  # Mondays at 08:00 (uses TZ below)
  workflow_dispatch:
    inputs:
      input_dir:
        description: "Override INPUT_DIR (repo-relative or absolute; e.g. logs or $GITHUB_WORKSPACE/logs)"
        required: false
        type: string
      week_scope:
        description: "Week to summarize: last (default) or this"
        required: false
        default: "last"
        type: string

jobs:
  run:
    runs-on: ubuntu-latest
    env:
      TZ: ${{ vars.DIGEST_TZ || 'UTC' }}  # e.g. America/Chicago or UTC

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install team-digest
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install "team-digest>=1.1.6,<2"

      # ---------- Resolve INPUT_DIR (no heredocs; parser-safe) ----------
      - name: Resolve INPUT_DIR (override → repo var → logs/)
        id: resolve
        shell: bash
        env:
          INPUT_DIR_OVERRIDE: ${{ github.event.inputs.input_dir }}
          VARS_DIGEST_INPUT_DIR: ${{ vars.DIGEST_INPUT_DIR }}
        run: |
          set -euo pipefail
          CANDIDATE="${INPUT_DIR_OVERRIDE:-}"
          if [ -z "$CANDIDATE" ] && [ -n "${VARS_DIGEST_INPUT_DIR:-}" ]; then
            CANDIDATE="${VARS_DIGEST_INPUT_DIR}"
          fi
          [ -z "$CANDIDATE" ] && CANDIDATE="logs"

          # Expand literal $GITHUB_WORKSPACE prefix if the user typed it
          if [[ "$CANDIDATE" == '$GITHUB_WORKSPACE'* ]]; then
            CANDIDATE="${GITHUB_WORKSPACE}${CANDIDATE#\$GITHUB_WORKSPACE}"
          fi

          # If relative, make it repo-absolute
          if [[ "$CANDIDATE" != /* ]]; then
            CANDIDATE="${GITHUB_WORKSPACE%/}/${CANDIDATE#./}"
          fi

          # Canonicalize with a one-liner (no heredoc)
          INPUT_DIR="$(python -c "import os,sys; print(os.path.abspath(sys.argv[1]))" "$CANDIDATE")"

          echo "Resolved INPUT_DIR=$INPUT_DIR"
          echo "INPUT_DIR=$INPUT_DIR" >> "$GITHUB_ENV"

      # ---------- Week window (Mon..Sun) ----------
      - name: Compute week window (Mon..Sun)
        shell: bash
        env:
          WEEK_SCOPE_IN: ${{ github.event.inputs.week_scope }}
        run: |
          set -euo pipefail
          scope="${WEEK_SCOPE_IN:-last}"
          scope="${scope,,}"
          if [[ "$scope" == this* ]]; then
            MON=$(date +%F -d "monday this week")
          else
            MON=$(date +%F -d "monday last week")
          fi
          SUN=$(date +%F -d "$MON +6 days")
          echo "FROM=$MON" | tee -a "$GITHUB_ENV"
          echo "TO=$SUN"   | tee -a "$GITHUB_ENV"
          echo "Window: $MON .. $SUN"

      # ---------- Diagnostics (prove what the runner sees) ----------
      - name: Diagnostics — repo & logs presence
        shell: bash
        run: |
          set -euo pipefail
          echo "pwd=$(pwd)"
          echo "GITHUB_WORKSPACE=$GITHUB_WORKSPACE"
          echo
          echo "Tracked files under logs/ (git):"
          git ls-files logs || true
          echo
          echo "List INPUT_DIR content:"
          if [ -d "$INPUT_DIR" ]; then
            ls -la "$INPUT_DIR" || true
          else
            echo "(INPUT_DIR does not exist)"
          fi

      # ---------- Normalize & retime note files ----------
      - name: Normalize / retime logs (safe edits)
        shell: bash
        run: |
          set -euo pipefail
          shopt -s nullglob
          for f in "$INPUT_DIR"/notes-????-??-??.*; do
            base="$(basename "$f")"
            datepart="${base#notes-}"; datepart="${datepart%%.*}"
            # Stamp mtime to noon UTC to avoid DST edges
            touch -m -d "${datepart} 12:00:00" "$f" || true
            # Normalize newlines/bullets/escapes/smart dashes
            sed -i \
              -e 's/\r$//' \
              -e 's/•\t/- /g' \
              -e 's/• /- /g' \
              -e 's/\\#/#/g' \
              -e 's/\\\[/[/' \
              -e 's/\\-/-/g' \
              -e 's/–/-/g' \
              -e 's/—/-/g' \
              "$f" || true
          done

      # ---------- Match files by filename date within Mon..Sun ----------
      - name: Diagnostics — match notes by filename date
        shell: bash
        run: |
          set -euo pipefail
          echo "Matching notes-YYYY-MM-DD.* within $FROM..$TO:"
          root="${INPUT_DIR%/}"
          found=()
          shopt -s nullglob
          for path in "$root"/notes-*; do
            name="$(basename "$path")"
            if [[ "$name" =~ ^notes-([0-9]{4}-[0-9]{2}-[0-9]{2})\.(md|markdown|txt)$ ]]; then
              d="${BASH_REMATCH[1]}"
              if [[ "$d" >="$FROM" && "$d" <="$TO" ]]; then
                found+=("$name")
              fi
            fi
          done
          if ((${#found[@]})); then
            IFS=$'\n' sorted=($(printf '%s\n' "${found[@]}" | sort)); unset IFS
            echo "MATCHES: ${sorted[*]}"
          else
            echo "MATCHES: (none)"
          fi

      # ---------- Generate digest ----------
      - name: Generate weekly digest
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p outputs
          team-digest --input "$INPUT_DIR" --from "$FROM" --to "$TO" --format md -o outputs/weekly.md
          echo '---- Preview (first 60 lines) ----'
          head -n 60 outputs/weekly.md || true

      # ---------- Optional: sort Actions by priority ----------
      - name: Sort Actions by priority (best effort)
        shell: bash
        continue-on-error: true
        run: |
          python -c "import re,io,sys; p='outputs/weekly.md'; 
t=io.open(p,'r',encoding='utf-8').read() if __import__('os').path.exists(p) else None
import os
if t:
  m=re.search(r'^##\\s+Actions\\s*$', t, re.M)
  if m:
    start=m.end()
    m2=re.search(r'^##\\s+\\w+', t[start:], re.M)
    end=start+(m2.start() if m2 else len(t)-start)
    block=t[start:end]
    lines=block.splitlines()
    bullets=[ln for ln in lines if re.match(r'^\\s*[-*]\\s+', ln)]
    others=[ln for ln in lines if ln not in bullets]
    def key(ln): 
      s=ln.lower()
      return 0 if '[high]' in s else (1 if '[medium]' in s else (2 if '[low]' in s else 3))
    ordered=sorted(bullets,key=key)
    joined='\\n'.join(ordered+([''] if ordered and (others and others[0].strip()) else [])+others)
    new=t[:start]+'\\n'+joined.strip('\\n')+'\\n'+t[end:]
    io.open(p,'w',encoding='utf-8').write(new)"

      # ---------- Slack (optional) ----------
      - name: Resolve Slack webhook (optional)
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${{ secrets.SLACK_WEBHOOK_URL }}" ]; then
            echo "SLACK_WEBHOOK=${{ secrets.SLACK_WEBHOOK_URL }}" >> "$GITHUB_ENV"
          elif [ -n "${{ secrets.SLACK_WEBHOOK }}" ]; then
            echo "SLACK_WEBHOOK=${{ secrets.SLACK_WEBHOOK }}" >> "$GITHUB_ENV"
          else
            echo "SLACK_WEBHOOK=" >> "$GITHUB_ENV"
          fi

      - name: Post to Slack (if webhook is set)
        if: env.SLACK_WEBHOOK != ''
        shell: bash
        run: |
          set -euo pipefail
          PAYLOAD=$(jq -Rs --arg pre '```' '{text: ($pre + . + $pre)}' < outputs/weekly.md)
          curl -fsSL -H 'Content-Type: application/json' --data-raw "$PAYLOAD" "$SLACK_WEBHOOK"

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: weekly-digest
          path: outputs/**
