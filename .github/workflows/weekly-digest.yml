name: Weekly Digest (last full week)

on:
  schedule:
    - cron: "0 8 * * 1"   # Mondays at 08:00 in your TZ (see DIGEST_TZ)
  workflow_dispatch:
    inputs:
      input_dir:
        description: "Override INPUT_DIR (repo-relative or absolute)"
        required: false
        type: string

jobs:
  run:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    env:
      TZ: ${{ vars.DIGEST_TZ || 'UTC' }}
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install team-digest
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install "team-digest>=1.1.6,<2"

      - name: Resolve INPUT_DIR (override → repo var → logs/)
        shell: bash
        run: |
          set -euo pipefail
          CANDIDATE="${{ github.event.inputs.input_dir }}"
          if [ -z "$CANDIDATE" ] && [ -n "${{ vars.DIGEST_INPUT_DIR }}" ]; then
            CANDIDATE="${{ vars.DIGEST_INPUT_DIR }}"
          fi
          [ -z "$CANDIDATE" ] && CANDIDATE="logs"

          if [ -d "$CANDIDATE" ]; then
            INPUT_DIR="$CANDIDATE"
          elif [ -d "$GITHUB_WORKSPACE/$CANDIDATE" ]; then
            INPUT_DIR="$GITHUB_WORKSPACE/$CANDIDATE"
          else
            INPUT_DIR="$CANDIDATE"
          fi

          echo "Resolved INPUT_DIR=$INPUT_DIR"
          echo "INPUT_DIR=$INPUT_DIR" >> "$GITHUB_ENV"

      - name: Compute last full calendar week (Mon..Sun) in TZ
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY' > _range.env
import os, datetime as dt
try:
    from zoneinfo import ZoneInfo
    z = ZoneInfo(os.environ.get("TZ","UTC"))
except Exception:
    z = None

today = dt.datetime.now(tz=z).date() if z else dt.datetime.utcnow().date()
# Monday=0 .. Sunday=6 for the CURRENT week
current_monday = today - dt.timedelta(days=today.weekday())
# Last week's Monday/Sunday
last_monday = current_monday - dt.timedelta(days=7)
last_sunday  = last_monday + dt.timedelta(days=6)

print(f"FROM={last_monday}")
print(f"TO={last_sunday}")
PY
          cat _range.env | tee -a "$GITHUB_ENV"
          echo "Range: $(cat _range.env)"

      - name: Normalize & retime logs (markdown + mtime from filename)
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
import os, re, io, datetime as dt, pathlib as p

root = p.Path(os.environ["INPUT_DIR"])
pat = re.compile(r"^notes-(\d{4}-\d{2}-\d{2})\.(md|markdown|txt)$", re.I)
sect = {"summary","decisions","actions","risks","dependencies","notes"}

def normalize(txt: str) -> str:
    txt = txt.replace("\r\n", "\n").replace("•\t", "- ").replace("• ", "- ")
    txt = re.sub(r"\\#", "#", txt)
    txt = re.sub(r"\\\[(?=[^\]]+\])", "[", txt)
    out = []
    for line in txt.splitlines():
        s = line.strip().lower()
        if s in sect and not line.lstrip().startswith("#"):
            out.append("## " + line.strip())
        else:
            out.append(line)
    return "\n".join(out).strip() + "\n"

if root.exists():
    for f in root.rglob("*"):
        if not f.is_file():
            continue
        m = pat.match(f.name)
        try:
            t = f.read_text(encoding="utf-8", errors="replace")
        except Exception:
            t = io.open(f, "r", encoding="utf-8", errors="replace").read()
        new = normalize(t)
        if new != t:
            f.write_text(new, encoding="utf-8")
        if m:
            day = dt.date.fromisoformat(m.group(1))
            noon = dt.datetime.combine(day, dt.time(12, 0))
            ts = noon.timestamp()
            os.utime(f, (ts, ts))
print("Normalization complete.")
PY

      - name: List candidate files (diagnostics)
        shell: bash
        run: |
          set -euo pipefail
          echo "All files in $INPUT_DIR:"; ls -la "$INPUT_DIR" || true; echo
          echo "Files matching notes-YYYY-MM-DD.* in $FROM..$TO:"
          python - <<'PY'
import os, re, datetime as dt, pathlib as p
d = p.Path(os.environ["INPUT_DIR"])
frm = dt.date.fromisoformat(os.environ["FROM"])
to  = dt.date.fromisoformat(os.environ["TO"])
pat = re.compile(r"^notes-(\d{4}-\d{2}-\d{2})\.(md|markdown|txt)$", re.I)
matches = []
if d.is_dir():
    for f in sorted(d.iterdir()):
        m = pat.match(f.name)
        if not m: continue
        day = dt.date.fromisoformat(m.group(1))
        if frm <= day <= to:
            matches.append(f.name)
print("MATCHES:", ", ".join(matches) if matches else "(none)")
PY

      - name: Generate weekly digest
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p outputs
          team-digest --input "$INPUT_DIR" --from "$FROM" --to "$TO" --format md -o outputs/weekly.md
          echo '---- Preview (first 40 lines) ----'
          head -n 40 outputs/weekly.md || true

      - name: Resolve Slack webhook (optional)
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${{ secrets.SLACK_WEBHOOK_URL }}" ]; then
            echo "SLACK_WEBHOOK=${{ secrets.SLACK_WEBHOOK_URL }}" >> "$GITHUB_ENV"
          elif [ -n "${{ secrets.SLACK_WEBHOOK }}" ]; then
            echo "SLACK_WEBHOOK=${{ secrets.SLACK_WEBHOOK }}" >> "$GITHUB_ENV"
          else
            echo "SLACK_WEBHOOK=" >> "$GITHUB_ENV"
          fi

      - name: Post to Slack (if webhook is set)
        if: env.SLACK_WEBHOOK != ''
        shell: bash
        run: |
          set -euo pipefail
          PAYLOAD=$(jq -Rs --arg pre '```' '{text: ($pre + . + $pre)}' < outputs/weekly.md)
          curl -fsSL -H 'Content-Type: application/json' --data-raw "$PAYLOAD" "$SLACK_WEBHOOK"

      - uses: actions/upload-artifact@v4
        with:
          name: weekly-digest
          path: outputs/**
